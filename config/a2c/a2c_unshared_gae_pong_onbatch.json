{
    "agent_cfg":{
        "algorithm_cfg":{
            "name":"A2C",
            "var_schedule_cfg":null,
            "gamma":0.99,
            "rets_mean_baseline":false,
            "policy_loss_var":1,
            "value_loss_var":0.7,
            "entropy_reg_var_cfg":{
                "name":"fixed",
                "var_start":0.01,
                "var_end":0.01,
                "star_epoch":0,
                "end_epoch":0
            },
            "n_step_returns":null,
            "lbd":0.95
        },
        "net_cfg":{
            "actor_net_cfg":{
                "name":"ConvNet",
                "conv_hid_layers":[
                    [32, 8, 4, 0, 1],
                    [64, 4, 2, 0, 1],
                    [32, 3, 1, 0, 1]
                ],
                "fc_hid_layers":[512],
                "hid_layers_activation":"relu",
                "out_layer_activation":"tanh",
                "normalize":true,
                "batch_norm":true
            },
            "critic_net_cfg":{
                "name":"ConvNet",
                "conv_hid_layers":[
                    [32, 8, 4, 0, 1],
                    [64, 4, 2, 0, 1],
                    [32, 3, 1, 0, 1]
                ],
                "fc_hid_layers":[512],
                "hid_layers_activation":"relu",
                "out_layer_activation":"tanh",
                "normalize":true,
                "batch_norm":true
            }
        },
        "optimizer_cfg":{
            "actor_optim_cfg":{
                "name":"adam",
                "lr":1e-3,
                "weight_decay": 1e-08,
                "betas": [
                    0.9,
                    0.999
                ]
            },
            "critic_optim_cfg":{
                "name":"adam",
                "lr":1e-3,
                "weight_decay": 1e-08,
                "betas": [
                    0.9,
                    0.999
                ]
            }
        },
        "lr_schedule_cfg":null,
        "memory_cfg":{
            "name":"OnPolicyBatch"
        },
        "max_epoch":10000,
        "explore_times_per_train":1,
        "train_exp_size":64,
        "batch_learn_times_per_train":4
    },
    "env":{
        "name":"Pong",
        "solved_total_reward":20,
        "finish_total_reward":21,
        "survival_T":100000
    },
    "model_path":null,
    "is_gpu_available":true,
    "valid":{
        "valid_step":100,
        "valid_times":5,
        "not_improve_finish_step":5
    }
}